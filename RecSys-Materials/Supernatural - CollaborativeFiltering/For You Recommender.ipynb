{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-surprise\n",
    "# !pip install snowflake-connector-python\n",
    "# !pip install \"snowflake-connector-python[pandas]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Hello World\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from snowflake import connector\n",
    "import pandas as pd\n",
    "\n",
    "conn = connector.connect(\n",
    "    user='kliantono',\n",
    "    password='ford.SIG7tuch_grar',\n",
    "    account='ada15167',\n",
    "    warehouse='COMPUTE_WH',\n",
    "    database='WITHIN'\n",
    ")\n",
    "\n",
    "cur_interactions = conn.cursor()\n",
    "cur_items = conn.cursor()\n",
    "cur_ratings = conn.cursor()\n",
    "\n",
    "interactions_sql = '''\n",
    "    select\n",
    "    *\n",
    "    from (\n",
    "        select\n",
    "            ws.USER_ID\n",
    "            , ws.WORKOUT_ID as item_id\n",
    "            , date_part('epoch_millisecond', ws.CREATED_AT) as timestamp\n",
    "            -- Map workout 'starts' to click\n",
    "            , 'Click' as event_type\n",
    "            , null as event_value\n",
    "        from within.pgprodflow.workout_sessions ws\n",
    "        join within.pgprodflow.workouts w\n",
    "            on ws.WORKOUT_ID = w.ID\n",
    "        where ws.CREATED_AT >= '2020-04-23'\n",
    "            and w.WORKOUT_TYPE in ('classic', 'boxing')\n",
    "            and w.ID NOT IN (1407, 1405, 1361, 1319, 965)\n",
    "            and ws.CREATED_AT > w.LAUNCH_DATE\n",
    "            and ws.user_id NOT IN ('Ua61ZFw', 'Uq6knIA', 'UkgX8SQ', 'UKXQuLg', 'UQM6URw', 'Uyyo4Kw')\n",
    "\n",
    "        UNION\n",
    "\n",
    "        select\n",
    "            ws.USER_ID\n",
    "            , ws.WORKOUT_ID as item_id\n",
    "            , date_part('epoch_millisecond', ws.CREATED_AT) as timestamp\n",
    "            -- Map workout completes to watch\n",
    "            , 'Watch' as event_type\n",
    "            , ws.TOTAL_SCORE as event_value\n",
    "        from within.pgprodflow.workout_sessions ws\n",
    "        join within.pgprodflow.workouts w\n",
    "            on ws.WORKOUT_ID = w.ID\n",
    "        where ws.CREATED_AT >= '2020-04-23'\n",
    "            and w.WORKOUT_TYPE in ('classic', 'boxing')\n",
    "            and w.ID NOT IN (1407, 1405, 1361, 1319, 965)\n",
    "            and ws.CREATED_AT > w.LAUNCH_DATE\n",
    "            -- use the incomplete flag to determine workout complete\n",
    "            and ws.INCOMPLETE = false\n",
    "            and ws.user_id NOT IN ('Ua61ZFw', 'Uq6knIA', 'UkgX8SQ', 'UKXQuLg', 'UQM6URw', 'Uyyo4Kw')\n",
    "        LIMIT 30000\n",
    "        ) a\n",
    "\n",
    "    UNION\n",
    "\n",
    "    select\n",
    "    *\n",
    "    from (\n",
    "        select\n",
    "            ws.USER_ID\n",
    "            , ws.WORKOUT_ID as item_id\n",
    "            , date_part('epoch_millisecond', ws.CREATED_AT) as timestamp\n",
    "            -- Map workout 'starts' to click\n",
    "            , 'Click' as event_type\n",
    "            , null as event_value\n",
    "        from within.pgprodflow.workout_sessions ws\n",
    "        join within.pgprodflow.workouts w\n",
    "            on ws.WORKOUT_ID = w.ID\n",
    "        where ws.CREATED_AT >= '2020-04-23'\n",
    "            and w.WORKOUT_TYPE in ('classic', 'boxing')\n",
    "            and w.ID NOT IN (1407, 1405, 1361, 1319, 965)\n",
    "            and ws.CREATED_AT > w.LAUNCH_DATE\n",
    "            and ws.user_id IN ('Ua61ZFw', 'Uq6knIA', 'UkgX8SQ', 'UKXQuLg', 'UQM6URw', 'Uyyo4Kw')\n",
    "\n",
    "        UNION\n",
    "\n",
    "        select\n",
    "            ws.USER_ID\n",
    "            , ws.WORKOUT_ID as item_id\n",
    "            , date_part('epoch_millisecond', ws.CREATED_AT) as timestamp\n",
    "            -- Map workout completes to watch\n",
    "            , 'Watch' as event_type\n",
    "            , ws.TOTAL_SCORE as event_value\n",
    "        from within.pgprodflow.workout_sessions ws\n",
    "        join within.pgprodflow.workouts w\n",
    "            on ws.WORKOUT_ID = w.ID\n",
    "        where ws.CREATED_AT >= '2020-04-23'\n",
    "            and w.WORKOUT_TYPE in ('classic', 'boxing')\n",
    "            and w.ID NOT IN (1407, 1405, 1361, 1319, 965)\n",
    "            and ws.CREATED_AT > w.LAUNCH_DATE\n",
    "            -- use the incomplete flag to determine workout complete\n",
    "            and ws.INCOMPLETE = false\n",
    "            and ws.user_id IN ('Ua61ZFw', 'Uq6knIA', 'UkgX8SQ', 'UKXQuLg', 'UQM6URw', 'Uyyo4Kw')\n",
    "        LIMIT 30000\n",
    "    ) b\n",
    "'''\n",
    "\n",
    "items_sql = '''\n",
    "    WITH genre AS (\n",
    "        SELECT\n",
    "            g.ID\n",
    "            , IFF(g.genres_list != '', g.genres_list, 'No Genre') AS genres\n",
    "            , IFF(g.collections_list != '', g.collections_list, 'No Collections') AS collections\n",
    "            , IFF(g.programs_list != '', g.programs_list, 'No Programs') AS programs\n",
    "            , IFF(g.carousels_list != '', g.carousels_list, 'No Carousels') AS carousels\n",
    "        FROM ( -- created a subquery to make it easier to read. We need another IFF function outside of the subquery,\n",
    "            -- because LISTAGG returns am empty STRING if we input NULL values, an we want to replace that will a STRING\n",
    "            -- declaring that there are e.g. 'No Genre', 'No Collections', etc.\n",
    "            SELECT\n",
    "                w.ID\n",
    "                -- There are multiple rows for the same WORKOUT_ID for each distinct TYPES & VALUE ({genre: pop, rock, collection: decades...}\n",
    "                -- Two VALUES for the same TYPE (e.g. genre: pop, rock), equates to two rows for the WORKOUT_ID\n",
    "                -- In order to aggregate the VALUES of the same TYPE into a single row for each WORKOUT_ID, we must use the IFF function\n",
    "                -- inside the LISTAGG function and provide a NULL value for the ELSE condition (if the WORKOUT_ID is missing the declared TYPE.)\n",
    "                -- If we substitute the NULL value with a STRING value (e.g.'No genre') for the ELSE condition, it would duplicate the STRING\n",
    "                -- for the number of rows there are for a WORKOUT_ID (e.g. 'Pop | No genre | No genre', instead of just 'Pop')\n",
    "                , LISTAGG(IFF(c.TYPE = 'genre', c.NAME, NULL), '|') WITHIN GROUP(ORDER BY c.\"ORDER\") AS genres_list\n",
    "                , LISTAGG(IFF(c.TYPE = 'collection', c.NAME, NULL), '|') WITHIN GROUP(ORDER BY c.\"ORDER\") AS collections_list\n",
    "                , LISTAGG(IFF(c.TYPE = 'program', c.NAME, NULL), '|') WITHIN GROUP(ORDER BY c.\"ORDER\") AS programs_list\n",
    "                , LISTAGG(IFF(c.TYPE = 'carousel', c.NAME, NULL), '|') WITHIN GROUP(ORDER BY c.\"ORDER\") AS carousels_list\n",
    "            FROM WITHIN.PGPRODFLOW.WORKOUTS w\n",
    "            LEFT JOIN WITHIN.PGPRODFLOW.CATEGORY_WORKOUTS cw ON cw.WORKOUT_ID = w.ID\n",
    "            LEFT JOIN WITHIN.PGPRODFLOW.CATEGORIES c ON c.ID = cw.CATEGORY_ID\n",
    "            WHERE 1=1\n",
    "                -- Has to be a workout in headset by the current date, no tutorials or demos, only boxing and flow\n",
    "                AND w.DISABLED != TRUE\n",
    "                AND w.VISIBILITY = 'public'\n",
    "                AND w.IS_LIFECYCLE = 0\n",
    "                AND w.WORKOUT_TYPE in ('classic', 'boxing')\n",
    "                AND w.ID NOT IN (1407, 1405, 1361, 1319, 965)\n",
    "                AND w.LAUNCH_DATE <= CURRENT_DATE()\n",
    "                AND cw.PUBLISHED_VERSION = 1\n",
    "            GROUP BY 1\n",
    "            ORDER BY 1\n",
    "        ) g\n",
    "    )\n",
    "\n",
    "    , rating AS (\n",
    "        -- Normalize ratings to the first 14 days after launch\n",
    "        SELECT\n",
    "            r.TABLE_ID,\n",
    "            AVG(r.RATING) avg_rating\n",
    "        FROM WITHIN.PGPRODFLOW.RATINGS r\n",
    "        LEFT JOIN WITHIN.PGPRODFLOW.WORKOUTS w ON w.ID = r.TABLE_ID\n",
    "        WHERE 1=1\n",
    "            -- Has to be a workout in headset by the current date, no tutorials or demos, only boxing and flow\n",
    "            AND r.RATING != 0\n",
    "            AND r.CREATED_AT < DATEADD('DAY', 14, w.LAUNCH_DATE)\n",
    "            AND w.LAUNCH_DATE <= CURRENT_DATE()\n",
    "            AND w.DISABLED != TRUE\n",
    "            AND w.VISIBILITY = 'public'\n",
    "            AND w.IS_LIFECYCLE = 0\n",
    "            AND w.WORKOUT_TYPE in ('classic', 'boxing')\n",
    "            AND w.ID NOT IN (1407, 1405, 1361, 1319, 965)\n",
    "        GROUP BY 1\n",
    "    )\n",
    "\n",
    "    SELECT\n",
    "        w.ID AS workoutId -- WORKOUT_ID\n",
    "        , w.TITLE AS title\n",
    "        --, ROUND(r.AVG_RATING, 2) AS AVERAGE_RATING -- RATING\n",
    "        --, DATE_PART('epoch_millisecond', w.LAUNCH_DATE) AS CREATION_TIMESTAMP -- LAUNCH_TIMESTAMP\n",
    "        --, IFF(wi.NAME IS NOT NULL, wi.NAME, NULL) AS INTENSITY\n",
    "        --, IFF(g.genres IS NOT NULL, g.genres, NULL) AS genres\n",
    "        , IFF(g.genres IS NOT NULL, g.genres, 'No genre') AS genres\n",
    "        --, IFF(g.collections IS NOT NULL, g.collections, NULL) AS COLLECTIONS\n",
    "    --     , IFF(g.programs IS NOT NULL, g.programs, NULL) AS PROGRAMS\n",
    "        --, IFF(g.carousels IS NOT NULL, g.carousels, NULL) AS CAROUSELS\n",
    "        --, w.WORKOUT_TYPE AS CONTENT_CLASSIFICATION -- WORKOUT_TYPE\n",
    "        --, CONCAT(i.FIRST_NAME, ' ', i.LAST_NAME) AS CONTENT_OWNER -- COACH\n",
    "        --, ROUND(w.DURATION / 60, 2) AS DURATION -- DURATION\n",
    "        --, w.DESCRIPTION -- PRODUCT_DESCRIPTION\n",
    "    FROM WITHIN.PGPRODFLOW.WORKOUTS w\n",
    "    LEFT JOIN WITHIN.PGPRODFLOW.WORKOUT_INTENSITY wi ON wi.id = w.intensity_id\n",
    "    LEFT JOIN WITHIN.PGPRODFLOW.INSTRUCTOR i ON i.id = w.instructor_id\n",
    "    LEFT JOIN rating r ON r.table_id = w.id\n",
    "    LEFT JOIN genre g ON g.ID = w.ID\n",
    "    WHERE 1=1\n",
    "        -- Has to be a workout in headset by the current date, no tutorials or demos, only boxing and flow\n",
    "        AND w.LAUNCH_DATE <= CURRENT_DATE()\n",
    "        AND w.DISABLED != TRUE\n",
    "        AND w.VISIBILITY = 'public'\n",
    "        AND w.IS_LIFECYCLE = 0\n",
    "        AND w.WORKOUT_TYPE in ('classic', 'boxing')\n",
    "        AND w.ID NOT IN (1407, 1405, 1361, 1319, 965)\n",
    "    ORDER BY 1\n",
    "'''\n",
    "\n",
    "ratings_sql = '''\n",
    "    SELECT\n",
    "    *\n",
    "    FROM (\n",
    "        SELECT\n",
    "            AUTHOR_ID AS userId\n",
    "            , TABLE_ID AS workoutId\n",
    "            , RATING AS rating\n",
    "            --# , DATE_PART('epoch_millisecond', CREATED_AT) as timestamp\n",
    "        FROM WITHIN.PGPRODFLOW.RATINGS r\n",
    "        JOIN WITHIN.PGPRODFLOW.WORKOUTS w ON w.ID = r.TABLE_ID\n",
    "        WHERE 1=1\n",
    "            AND r.RATING != 0\n",
    "            AND w.LAUNCH_DATE <= CURRENT_DATE()\n",
    "            AND w.DISABLED != TRUE\n",
    "            AND w.VISIBILITY = 'public'\n",
    "            AND w.IS_LIFECYCLE = 0\n",
    "            AND w.WORKOUT_TYPE in ('classic', 'boxing')\n",
    "            AND w.ID NOT IN (1407, 1405, 1361, 1319, 965)\n",
    "            AND AUTHOR_ID NOT IN ('Ua61ZFw', 'Uq6knIA', 'UkgX8SQ', 'UKXQuLg', 'UQM6URw', 'Uyyo4Kw')\n",
    "        LIMIT 30000\n",
    "    ) a\n",
    "\n",
    "    UNION\n",
    "\n",
    "    SELECT\n",
    "    *\n",
    "    FROM (\n",
    "        SELECT\n",
    "            AUTHOR_ID AS userId\n",
    "            , TABLE_ID AS workoutId\n",
    "            , RATING AS rating\n",
    "            --# , DATE_PART('epoch_millisecond', CREATED_AT) as timestamp\n",
    "        FROM WITHIN.PGPRODFLOW.RATINGS r\n",
    "        JOIN WITHIN.PGPRODFLOW.WORKOUTS w ON w.ID = r.TABLE_ID\n",
    "        WHERE 1=1\n",
    "            AND r.RATING != 0\n",
    "            AND w.LAUNCH_DATE <= CURRENT_DATE()\n",
    "            AND w.DISABLED != TRUE\n",
    "            AND w.VISIBILITY = 'public'\n",
    "            AND w.IS_LIFECYCLE = 0\n",
    "            AND w.WORKOUT_TYPE in ('classic', 'boxing')\n",
    "            AND w.ID NOT IN (1407, 1405, 1361, 1319, 965)\n",
    "            AND AUTHOR_ID IN ('Ua61ZFw', 'Uq6knIA', 'UkgX8SQ', 'UKXQuLg', 'UQM6URw', 'Uyyo4Kw')\n",
    "        ORDER BY 1\n",
    "        LIMIT 30000\n",
    "    ) b\n",
    "'''\n",
    "\n",
    "# cur_interactions.execute(interactions_sql)\n",
    "# cur_items.execute(items_sql)\n",
    "# cur_ratings.execute(ratings_sql)\n",
    "\n",
    "try:\n",
    "    cur_interactions.execute(interactions_sql)\n",
    "    all_rows_interactions = cur_interactions.fetchall()\n",
    "    num_fields_interactions = len(cur_interactions.description)\n",
    "    field_names_interactions = [i[0] for i in cur_interactions.description]\n",
    "finally:\n",
    "    cur_interactions.close()\n",
    "\n",
    "interactions_df = pd.DataFrame(all_rows_interactions)\n",
    "interactions_df.columns = field_names_interactions\n",
    "\n",
    "\n",
    "try:\n",
    "    cur_items.execute(items_sql)\n",
    "    all_rows_items = cur_items.fetchall()\n",
    "    num_fields_items = len(cur_items.description)\n",
    "    field_names_items = [i[0] for i in cur_items.description]\n",
    "finally:\n",
    "    cur_items.close()\n",
    "\n",
    "items_df = pd.DataFrame(all_rows_items)\n",
    "items_df.columns = field_names_items\n",
    "\n",
    "\n",
    "try:\n",
    "    cur_ratings.execute(ratings_sql)\n",
    "    all_rows_ratings = cur_ratings.fetchall()\n",
    "    num_fields_ratings = len(cur_ratings.description)\n",
    "    field_names_ratings = [i[0] for i in cur_ratings.description]\n",
    "finally:\n",
    "    cur_ratings.close()\n",
    "\n",
    "ratings_df = pd.DataFrame(all_rows_ratings)\n",
    "ratings_df.columns = field_names_ratings\n",
    "\n",
    "\n",
    "# interactions_df = cur_interactions.fetch_pandas_all()\n",
    "# items_df = cur_items.fetch_pandas_all()\n",
    "# ratings_df = cur_ratings.fetch_pandas_all()\n",
    "\n",
    "# cur_interactions.close()\n",
    "# cur_items.close()\n",
    "# cur_ratings.close()\n",
    "\n",
    "# interactions_df.to_csv('../ml-latest-small/workout_interactions.csv', header=True)\n",
    "# items_df.to_csv('../ml-latest-small/workout_items.csv', index=False, header=True)\n",
    "# ratings_df.to_csv('../ml-latest-small/workout_ratings.csv', index=False, header=True)\n",
    "\n",
    "# print(interactions_df.head())\n",
    "# print(items_df.head())\n",
    "# print(ratings_df.head())\n",
    "\n",
    "# print(df.dtypes)\n",
    "# print(df.info())\n",
    "# print(df.describe())\n",
    "# print(isinstance(df, pd.DataFrame))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class WorkoutLens:\n",
    "\n",
    "    workoutID_to_name = {}\n",
    "    name_to_workoutID = {}\n",
    "    ratingsPath = ratings_df\n",
    "    workoutsPath = items_df\n",
    "\n",
    "    def loadWorkoutLensLatestSmall(self):\n",
    "\n",
    "        # Look for files relative to the directory we are running from\n",
    "        os.chdir(os.path.dirname(sys.argv[0]))\n",
    "\n",
    "        ratingsDataset = 0\n",
    "        self.workoutID_to_name = {}\n",
    "        self.name_to_workoutID = {}\n",
    "\n",
    "#         reader = Reader(rating_scale=(1, 5))\n",
    "        reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
    "\n",
    "\n",
    "        ratingsDataset = Dataset.load_from_df(self.ratingsPath, reader=reader)\n",
    "\n",
    "        for row in self.workoutsPath.itertuples():\n",
    "            # workoutID = int(row['WORKOUTID'])\n",
    "            # workoutName = row['TITLE']\n",
    "            workoutID = int(row[1])\n",
    "            workoutName = row[2]\n",
    "            self.workoutID_to_name[workoutID] = workoutName\n",
    "            self.name_to_workoutID[workoutName] = workoutID\n",
    "\n",
    "        return ratingsDataset\n",
    "\n",
    "    def getUserRatings(self, user):\n",
    "        userRatings = []\n",
    "        hitUser = False\n",
    "\n",
    "        for row in self.ratingsPath.itertuples():\n",
    "            # userID = int(row['USERID'])\n",
    "            userID = int(row[1])\n",
    "            if (user == userID):\n",
    "                # workoutID = int(row['WORKOUTID'])\n",
    "                # rating = float(row['RATING'])\n",
    "                workoutID = int(row[2])\n",
    "                rating = float(row[3])\n",
    "                userRatings.append((workoutID, rating))\n",
    "                hitUser = True\n",
    "            if (hitUser and (user != userID)):\n",
    "                break\n",
    "\n",
    "        return userRatings\n",
    "\n",
    "    def getPopularityRanks(self):\n",
    "        ratings = defaultdict(int)\n",
    "        rankings = defaultdict(int)\n",
    "\n",
    "        for row in self.ratingsPath.itertuples():\n",
    "            # workoutID = int(row['WORKOUTID'])\n",
    "            workoutID = int(row[2])\n",
    "            ratings[workoutID] += 1\n",
    "\n",
    "        rank = 1\n",
    "        for workoutID, ratingCount in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "            rankings[workoutID] = rank\n",
    "            rank += 1\n",
    "\n",
    "        return rankings\n",
    "\n",
    "    def getGenres(self):\n",
    "        genres = defaultdict(list)\n",
    "        genreIDs = {}\n",
    "        maxGenreID = 0\n",
    "\n",
    "        for row in self.workoutsPath.itertuples():\n",
    "            # workoutID = int(row['WORKOUTID'])\n",
    "            # genreList = row['GENRES'].split('|')\n",
    "            workoutID = int(row[1])\n",
    "            genreList = row[3].split('|')\n",
    "            genreIDList = []\n",
    "            for genre in genreList:\n",
    "                if genre in genreIDs:\n",
    "                    genreID = genreIDs[genre]\n",
    "                else:\n",
    "                    genreID = maxGenreID\n",
    "                    genreIDs[genre] = genreID\n",
    "                    maxGenreID += 1\n",
    "                genreIDList.append(genreID)\n",
    "            genres[workoutID] = genreIDList\n",
    "\n",
    "        # Convert integer-encoded genre lists to bitfields that we can treat as vectors\n",
    "        for (workoutID, genreIDList) in genres.items():\n",
    "            bitfield = [0] * maxGenreID\n",
    "            for genreID in genreIDList:\n",
    "                bitfield[genreID] = 1\n",
    "            genres[workoutID] = bitfield\n",
    "\n",
    "        return genres\n",
    "\n",
    "    def getYears(self):\n",
    "        p = re.compile(r\"(?:\\((\\d{4})\\))?\\s*$\")\n",
    "        years = defaultdict(int)\n",
    "\n",
    "        for row in self.workoutsPath.itertuples():\n",
    "            # workoutID = int(row['WORKOUTID'])\n",
    "            # title = row['TITLE']\n",
    "            workoutID = int(row[1])\n",
    "            title = row[2]\n",
    "            m = p.search(title)\n",
    "            year = m.group(1)\n",
    "            if year:\n",
    "                years[workoutID] = int(year)\n",
    "\n",
    "        return years\n",
    "\n",
    "    def getMiseEnScene(self):\n",
    "        mes = defaultdict(list)\n",
    "        with open(\"LLVisualFeatures13K_Log.csv\", newline='') as csvfile:\n",
    "            mesReader = csv.reader(csvfile)\n",
    "            next(mesReader)\n",
    "            for row in mesReader:\n",
    "                workoutID = int(row[0])\n",
    "                avgShotLength = float(row[1])\n",
    "                meanColorVariance = float(row[2])\n",
    "                stddevColorVariance = float(row[3])\n",
    "                meanMotion = float(row[4])\n",
    "                stddevMotion = float(row[5])\n",
    "                meanLightingKey = float(row[6])\n",
    "                numShots = float(row[7])\n",
    "                mes[workoutID] = [avgShotLength, meanColorVariance, stddevColorVariance,\n",
    "                   meanMotion, stddevMotion, meanLightingKey, numShots]\n",
    "        return mes\n",
    "\n",
    "    def getWorkoutName(self, workoutID):\n",
    "        if workoutID in self.workoutID_to_name:\n",
    "            return self.workoutID_to_name[workoutID]\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "    def getWorkoutID(self, workoutName):\n",
    "        if workoutName in self.name_to_workoutID:\n",
    "            return self.name_to_workoutID[workoutName]\n",
    "        else:\n",
    "            return 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(interactions_df.size)\n",
    "print(interactions_df.memory_usage(index=True).sum())\n",
    "print(items_df.size)\n",
    "print(items_df.memory_usage(index=True).sum())\n",
    "print(ratings_df.size)\n",
    "print(ratings_df.memory_usage(index=True).sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "interactions_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "items_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict\n",
    "\n",
    "class RecommenderMetrics:\n",
    "\n",
    "    def MAE(predictions):\n",
    "        return accuracy.mae(predictions, verbose=False)\n",
    "\n",
    "    def RMSE(predictions):\n",
    "        return accuracy.rmse(predictions, verbose=False)\n",
    "\n",
    "    def GetTopN(predictions, n=20, minimumRating=4.0):\n",
    "        topN = defaultdict(list)\n",
    "\n",
    "\n",
    "        for userID, workoutID, actualRating, estimatedRating, _ in predictions:\n",
    "            if (estimatedRating >= minimumRating):\n",
    "                topN[int(userID)].append((int(workoutID), estimatedRating))\n",
    "\n",
    "        for userID, ratings in topN.items():\n",
    "            ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            topN[int(userID)] = ratings[:n]\n",
    "\n",
    "        return topN\n",
    "\n",
    "    def HitRate(topNPredicted, leftOutPredictions):\n",
    "        hits = 0\n",
    "        total = 0\n",
    "\n",
    "        # For each left-out rating\n",
    "        for leftOut in leftOutPredictions:\n",
    "            userID = leftOut[0]\n",
    "            leftOutWorkoutID = leftOut[1]\n",
    "            # Is it in the predicted top 20 for this user?\n",
    "            hit = False\n",
    "            for workoutID, predictedRating in topNPredicted[int(userID)]:\n",
    "                if (int(leftOutWorkoutID) == int(workoutID)):\n",
    "                    hit = True\n",
    "                    break\n",
    "            if (hit) :\n",
    "                hits += 1\n",
    "\n",
    "            total += 1\n",
    "\n",
    "        # Compute overall precision\n",
    "        return hits/total\n",
    "\n",
    "    def CumulativeHitRate(topNPredicted, leftOutPredictions, ratingCutoff=0):\n",
    "        hits = 0\n",
    "        total = 0\n",
    "\n",
    "        # For each left-out rating\n",
    "        for userID, leftOutWorkoutID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
    "            # Only look at ability to recommend things the users actually liked...\n",
    "            if (actualRating >= ratingCutoff):\n",
    "                # Is it in the predicted top 20 for this user?\n",
    "                hit = False\n",
    "                for workoutID, predictedRating in topNPredicted[int(userID)]:\n",
    "                    if (int(leftOutWorkoutID) == workoutID):\n",
    "                        hit = True\n",
    "                        break\n",
    "                if (hit) :\n",
    "                    hits += 1\n",
    "\n",
    "                total += 1\n",
    "\n",
    "        # Compute overall precision\n",
    "        return hits/total\n",
    "\n",
    "    def RatingHitRate(topNPredicted, leftOutPredictions):\n",
    "        hits = defaultdict(float)\n",
    "        total = defaultdict(float)\n",
    "\n",
    "        # For each left-out rating\n",
    "        for userID, leftOutWorkoutID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
    "            # Is it in the predicted top N for this user?\n",
    "            hit = False\n",
    "            for workoutID, predictedRating in topNPredicted[int(userID)]:\n",
    "                if (int(leftOutWorkoutID) == workoutID):\n",
    "                    hit = True\n",
    "                    break\n",
    "            if (hit) :\n",
    "                hits[actualRating] += 1\n",
    "\n",
    "            total[actualRating] += 1\n",
    "\n",
    "        # Compute overall precision\n",
    "        for rating in sorted(hits.keys()):\n",
    "            print(rating, hits[rating] / total[rating])\n",
    "\n",
    "    def AverageReciprocalHitRank(topNPredicted, leftOutPredictions):\n",
    "        summation = 0\n",
    "        total = 0\n",
    "        # For each left-out rating\n",
    "        for userID, leftOutWorkoutID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
    "            # Is it in the predicted top N for this user?\n",
    "            hitRank = 0\n",
    "            rank = 0\n",
    "            for workoutID, predictedRating in topNPredicted[int(userID)]:\n",
    "                rank = rank + 1\n",
    "                if (int(leftOutWorkoutID) == workoutID):\n",
    "                    hitRank = rank\n",
    "                    break\n",
    "            if (hitRank > 0) :\n",
    "                summation += 1.0 / hitRank\n",
    "\n",
    "            total += 1\n",
    "\n",
    "        return summation / total\n",
    "\n",
    "    # What percentage of users have at least one \"good\" recommendation\n",
    "    def UserCoverage(topNPredicted, numUsers, ratingThreshold=0):\n",
    "        hits = 0\n",
    "        for userID in topNPredicted.keys():\n",
    "            hit = False\n",
    "            for workoutID, predictedRating in topNPredicted[userID]:\n",
    "                if (predictedRating >= ratingThreshold):\n",
    "                    hit = True\n",
    "                    break\n",
    "            if (hit):\n",
    "                hits += 1\n",
    "\n",
    "        return hits / numUsers\n",
    "\n",
    "    def Diversity(topNPredicted, simsAlgo):\n",
    "        n = 0\n",
    "        total = 0\n",
    "        simsMatrix = simsAlgo.compute_similarities()\n",
    "        for userID in topNPredicted.keys():\n",
    "            pairs = itertools.combinations(topNPredicted[userID], 2)\n",
    "            for pair in pairs:\n",
    "                workout1 = pair[0][0]\n",
    "                workout2 = pair[1][0]\n",
    "                innerID1 = simsAlgo.trainset.to_inner_iid(str(workout1))\n",
    "                innerID2 = simsAlgo.trainset.to_inner_iid(str(workout2))\n",
    "                similarity = simsMatrix[innerID1][innerID2]\n",
    "                total += similarity\n",
    "                n += 1\n",
    "\n",
    "        S = total / n\n",
    "        return (1-S)\n",
    "\n",
    "    def Novelty(topNPredicted, rankings):\n",
    "        n = 0\n",
    "        total = 0\n",
    "        for userID in topNPredicted.keys():\n",
    "            for rating in topNPredicted[userID]:\n",
    "                workoutID = rating[0]\n",
    "                rank = rankings[workoutID]\n",
    "                total += rank\n",
    "                n += 1\n",
    "        return total / n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import LeaveOneOut\n",
    "from surprise import KNNBaseline\n",
    "\n",
    "class EvaluationData:\n",
    "\n",
    "    def __init__(self, data, popularityRankings):\n",
    "\n",
    "        self.rankings = popularityRankings\n",
    "\n",
    "        #Build a full training set for evaluating overall properties\n",
    "        self.fullTrainSet = data.build_full_trainset()\n",
    "        self.fullAntiTestSet = self.fullTrainSet.build_anti_testset()\n",
    "\n",
    "        #Build a 75/25 train/test split for measuring accuracy\n",
    "        self.trainSet, self.testSet = train_test_split(data, test_size=.25, random_state=1)\n",
    "\n",
    "        #Build a \"leave one out\" train/test split for evaluating top-N recommenders\n",
    "        #And build an anti-test-set for building predictions\n",
    "        LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
    "        for train, test in LOOCV.split(data):\n",
    "            self.LOOCVTrain = train\n",
    "            self.LOOCVTest = test\n",
    "\n",
    "        self.LOOCVAntiTestSet = self.LOOCVTrain.build_anti_testset()\n",
    "\n",
    "        #Compute similarty matrix between items so we can measure diversity\n",
    "        sim_options = {'name': 'cosine', 'user_based': False}\n",
    "        self.simsAlgo = KNNBaseline(sim_options=sim_options)\n",
    "        self.simsAlgo.fit(self.fullTrainSet)\n",
    "\n",
    "    def GetFullTrainSet(self):\n",
    "        return self.fullTrainSet\n",
    "\n",
    "    def GetFullAntiTestSet(self):\n",
    "        return self.fullAntiTestSet\n",
    "\n",
    "    def GetAntiTestSetForUser(self, testSubject):\n",
    "        trainset = self.fullTrainSet\n",
    "        fill = trainset.global_mean\n",
    "        anti_testset = []\n",
    "        u = trainset.to_inner_uid(str(testSubject))\n",
    "        user_items = set([j for (j, _) in trainset.ur[u]])\n",
    "        anti_testset += [(trainset.to_raw_uid(u), trainset.to_raw_iid(i), fill) for\n",
    "                                 i in trainset.all_items() if\n",
    "                                 i not in user_items]\n",
    "        return anti_testset\n",
    "\n",
    "    def GetTrainSet(self):\n",
    "        return self.trainSet\n",
    "\n",
    "    def GetTestSet(self):\n",
    "        return self.testSet\n",
    "\n",
    "    def GetLOOCVTrainSet(self):\n",
    "        return self.LOOCVTrain\n",
    "\n",
    "    def GetLOOCVTestSet(self):\n",
    "        return self.LOOCVTest\n",
    "\n",
    "    def GetLOOCVAntiTestSet(self):\n",
    "        return self.LOOCVAntiTestSet\n",
    "\n",
    "    def GetSimilarities(self):\n",
    "        return self.simsAlgo\n",
    "\n",
    "    def GetPopularityRankings(self):\n",
    "        return self.rankings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from RecommenderMetrics import RecommenderMetrics\n",
    "# from EvaluationData import EvaluationData\n",
    "\n",
    "class EvaluatedAlgorithm:\n",
    "\n",
    "    def __init__(self, algorithm, name):\n",
    "        self.algorithm = algorithm\n",
    "        self.name = name\n",
    "\n",
    "    def Evaluate(self, evaluationData, doTopN, n=20, verbose=True):\n",
    "        metrics = {}\n",
    "        # Compute accuracy\n",
    "        if (verbose):\n",
    "            print(\"Evaluating accuracy...\")\n",
    "        self.algorithm.fit(evaluationData.GetTrainSet())\n",
    "        predictions = self.algorithm.test(evaluationData.GetTestSet())\n",
    "        metrics[\"RMSE\"] = RecommenderMetrics.RMSE(predictions)\n",
    "        metrics[\"MAE\"] = RecommenderMetrics.MAE(predictions)\n",
    "\n",
    "        if (doTopN):\n",
    "            # Evaluate top-20 with Leave One Out testing\n",
    "            if (verbose):\n",
    "                print(\"Evaluating top-N with leave-one-out...\")\n",
    "            self.algorithm.fit(evaluationData.GetLOOCVTrainSet())\n",
    "            leftOutPredictions = self.algorithm.test(evaluationData.GetLOOCVTestSet())\n",
    "            # Build predictions for all ratings not in the training set\n",
    "            allPredictions = self.algorithm.test(evaluationData.GetLOOCVAntiTestSet())\n",
    "            # Compute top 20 recs for each user\n",
    "            topNPredicted = RecommenderMetrics.GetTopN(allPredictions, n)\n",
    "            if (verbose):\n",
    "                print(\"Computing hit-rate and rank metrics...\")\n",
    "            # See how often we recommended a workout the user actually rated\n",
    "            metrics[\"HR\"] = RecommenderMetrics.HitRate(topNPredicted, leftOutPredictions)\n",
    "            # See how often we recommended a workout the user actually liked\n",
    "            metrics[\"cHR\"] = RecommenderMetrics.CumulativeHitRate(topNPredicted, leftOutPredictions)\n",
    "            # Compute ARHR\n",
    "            metrics[\"ARHR\"] = RecommenderMetrics.AverageReciprocalHitRank(topNPredicted, leftOutPredictions)\n",
    "\n",
    "            #Evaluate properties of recommendations on full training set\n",
    "            if (verbose):\n",
    "                print(\"Computing recommendations with full data set...\")\n",
    "            self.algorithm.fit(evaluationData.GetFullTrainSet())\n",
    "            allPredictions = self.algorithm.test(evaluationData.GetFullAntiTestSet())\n",
    "            topNPredicted = RecommenderMetrics.GetTopN(allPredictions, n)\n",
    "            if (verbose):\n",
    "                print(\"Analyzing coverage, diversity, and novelty...\")\n",
    "            # Print user coverage with a minimum predicted rating of 4.0:\n",
    "            metrics[\"Coverage\"] = RecommenderMetrics.UserCoverage(  topNPredicted,\n",
    "                                                                   evaluationData.GetFullTrainSet().n_users,\n",
    "                                                                   ratingThreshold=4.0)\n",
    "            # Measure diversity of recommendations:\n",
    "            metrics[\"Diversity\"] = RecommenderMetrics.Diversity(topNPredicted, evaluationData.GetSimilarities())\n",
    "\n",
    "            # Measure novelty (average popularity rank of recommendations):\n",
    "            metrics[\"Novelty\"] = RecommenderMetrics.Novelty(topNPredicted,\n",
    "                                                            evaluationData.GetPopularityRankings())\n",
    "\n",
    "        if (verbose):\n",
    "            print(\"Analysis complete.\")\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def GetName(self):\n",
    "        return self.name\n",
    "\n",
    "    def GetAlgorithm(self):\n",
    "        return self.algorithm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # from WorkoutLens import WorkoutLens\n",
    "# from surprise import KNNBasic\n",
    "# import heapq\n",
    "# from collections import defaultdict\n",
    "# from operator import itemgetter\n",
    "# from surprise.model_selection import LeaveOneOut\n",
    "# # from RecommenderMetrics import RecommenderMetrics\n",
    "# # from EvaluationData import EvaluationData\n",
    "\n",
    "# def LoadWorkoutLensData():\n",
    "#     ml = WorkoutLens()\n",
    "#     print(\"Loading workout ratings...\")\n",
    "#     data = ml.loadWorkoutLensLatestSmall()\n",
    "#     print(\"\\nComputing workout popularity ranks so we can measure novelty later...\")\n",
    "#     rankings = ml.getPopularityRanks()\n",
    "#     return (ml, data, rankings)\n",
    "\n",
    "# ml, data, rankings = LoadWorkoutLensData()\n",
    "\n",
    "# evalData = EvaluationData(data, rankings)\n",
    "\n",
    "# # Train on leave-One-Out train set\n",
    "# trainSet = evalData.GetLOOCVTrainSet()\n",
    "# sim_options = {'name': 'cosine',\n",
    "#                'user_based': True\n",
    "#                }\n",
    "\n",
    "# model = KNNBasic(sim_options=sim_options)\n",
    "# model.fit(trainSet)\n",
    "# simsMatrix = model.compute_similarities()\n",
    "\n",
    "# leftOutTestSet = evalData.GetLOOCVTestSet()\n",
    "\n",
    "# # Build up dict to lists of (int(workoutID), predictedrating) pairs\n",
    "# topN = defaultdict(list)\n",
    "# k = 10\n",
    "# for uiid in range(trainSet.n_users):\n",
    "#     # Get top N similar users to this one\n",
    "#     similarityRow = simsMatrix[uiid]\n",
    "\n",
    "#     similarUsers = []\n",
    "#     for innerID, score in enumerate(similarityRow):\n",
    "#         if (innerID != uiid):\n",
    "#             similarUsers.append( (innerID, score) )\n",
    "\n",
    "#     kNeighbors = heapq.nlargest(k, similarUsers, key=lambda t: t[1])\n",
    "\n",
    "#     # Get the stuff they rated, and add up ratings for each item, weighted by user similarity\n",
    "#     candidates = defaultdict(float)\n",
    "#     for similarUser in kNeighbors:\n",
    "#         innerID = similarUser[0]\n",
    "#         userSimilarityScore = similarUser[1]\n",
    "#         theirRatings = trainSet.ur[innerID]\n",
    "#         for rating in theirRatings:\n",
    "#             candidates[rating[0]] += (rating[1] / 5.0) * userSimilarityScore\n",
    "\n",
    "#     # Build a dictionary of stuff the user has already seen\n",
    "#     watched = {}\n",
    "#     for itemID, rating in trainSet.ur[uiid]:\n",
    "#         watched[itemID] = 1\n",
    "\n",
    "#     # Get top-rated items from similar users:\n",
    "#     pos = 0\n",
    "#     for itemID, ratingSum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
    "#         if not itemID in watched:\n",
    "#             workoutID = trainSet.to_raw_iid(itemID)\n",
    "#             topN[int(trainSet.to_raw_uid(uiid))].append( (int(workoutID), 0.0) )\n",
    "#             pos += 1\n",
    "#             if (pos > 40):\n",
    "#                 break\n",
    "\n",
    "# # Measure\n",
    "# print(\"HR\", RecommenderMetrics.HitRate(topN, leftOutTestSet))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# User CF\n",
    "\n",
    "# from WorkoutLens import WorkoutLens\n",
    "from surprise import KNNBasic\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "\n",
    "# testSubject = 'Ua61ZFw' # Dan\n",
    "# testSubject = 'Uq6knIA' # Mom\n",
    "# testSubject = 'UkgX8SQ' # Alex\n",
    "# testSubject = 'UKXQuLg' # Sean\n",
    "testSubject = 'UQM6URw' # Jenn\n",
    "# testSubject = 'Uyyo4Kw' # Fharzana\n",
    "k = 10\n",
    "\n",
    "# Load our data set and compute the user similarity matrix\n",
    "ml = WorkoutLens()\n",
    "data = ml.loadWorkoutLensLatestSmall()\n",
    "\n",
    "trainSet = data.build_full_trainset()\n",
    "\n",
    "\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': True\n",
    "               }\n",
    "\n",
    "model = KNNBasic(sim_options=sim_options)\n",
    "model.fit(trainSet)\n",
    "simsMatrix = model.compute_similarities()\n",
    "\n",
    "# Get top N similar users to our test subject\n",
    "# (Alternate approach would be to select users up to some similarity threshold - try it!)\n",
    "testUserInnerID = trainSet.to_inner_uid(testSubject)\n",
    "similarityRow = simsMatrix[testUserInnerID]\n",
    "\n",
    "similarUsers = []\n",
    "for innerID, score in enumerate(similarityRow):\n",
    "    if (innerID != testUserInnerID):\n",
    "        similarUsers.append( (innerID, score) )\n",
    "\n",
    "kNeighbors = heapq.nlargest(k, similarUsers, key=lambda t: t[1])\n",
    "\n",
    "# Get the stuff they rated, and add up ratings for each item, weighted by user similarity\n",
    "candidates = defaultdict(float)\n",
    "for similarUser in kNeighbors:\n",
    "    innerID = similarUser[0]\n",
    "    userSimilarityScore = similarUser[1]\n",
    "    theirRatings = trainSet.ur[innerID]\n",
    "    for rating in theirRatings:\n",
    "        candidates[rating[0]] += (rating[1] / 5.0) * userSimilarityScore\n",
    "\n",
    "# Build a dictionary of stuff the user has already seen\n",
    "watched = {}\n",
    "for itemID, rating in trainSet.ur[testUserInnerID]:\n",
    "    watched[itemID] = 1\n",
    "\n",
    "# Get top-rated items from similar users:\n",
    "pos = 0\n",
    "for itemID, ratingSum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
    "    if not itemID in watched:\n",
    "        workoutID = trainSet.to_raw_iid(itemID)\n",
    "        print(ml.getWorkoutID(ml.getWorkoutName(int(workoutID))),ml.getWorkoutName(int(workoutID)),ratingSum)\n",
    "        pos += 1\n",
    "        if (pos > 10):\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Items CF\n",
    "\n",
    "# from WorkoutLens import WorkoutLens\n",
    "from surprise import KNNBasic\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "\n",
    "# testSubject = 'Ua61ZFw' # Dan\n",
    "# testSubject = 'Uq6knIA' # Mom\n",
    "# testSubject = 'UkgX8SQ' # Alex\n",
    "# testSubject = 'UKXQuLg' # Sean\n",
    "testSubject = 'UQM6URw' # Jenn\n",
    "# testSubject = 'Uyyo4Kw' # Fharzana\n",
    "k = 10\n",
    "\n",
    "ml = WorkoutLens()\n",
    "data = ml.loadWorkoutLensLatestSmall()\n",
    "\n",
    "trainSet = data.build_full_trainset()\n",
    "\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': False\n",
    "               }\n",
    "\n",
    "model = KNNBasic(sim_options=sim_options)\n",
    "model.fit(trainSet)\n",
    "simsMatrix = model.compute_similarities()\n",
    "\n",
    "testUserInnerID = trainSet.to_inner_uid(testSubject)\n",
    "\n",
    "# Get the top K items we rated\n",
    "testUserRatings = trainSet.ur[testUserInnerID]\n",
    "kNeighbors = heapq.nlargest(k, testUserRatings, key=lambda t: t[1])\n",
    "\n",
    "# Get similar items to stuff we liked (weighted by rating)\n",
    "candidates = defaultdict(float)\n",
    "for itemID, rating in kNeighbors:\n",
    "    similarityRow = simsMatrix[itemID]\n",
    "    for innerID, score in enumerate(similarityRow):\n",
    "        candidates[innerID] += score * (rating / 5.0)\n",
    "\n",
    "# Build a dictionary of stuff the user has already seen\n",
    "watched = {}\n",
    "for itemID, rating in trainSet.ur[testUserInnerID]:\n",
    "    watched[itemID] = 1\n",
    "\n",
    "# Get top-rated items from similar users:\n",
    "pos = 0\n",
    "for itemID, ratingSum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
    "    if not itemID in watched:\n",
    "        workoutID = trainSet.to_raw_iid(itemID)\n",
    "        print(ml.getWorkoutID(ml.getWorkoutName(int(workoutID))),ml.getWorkoutName(int(workoutID)), ratingSum)\n",
    "        pos += 1\n",
    "        if (pos > 10):\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}